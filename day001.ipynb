{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          2.64575131 -0.77459667  0.26306757  0.12381479]\n [ 1.         -0.37796447 -0.77459667 -0.25350148  0.46175632]\n [-1.         -0.37796447  1.29099445 -1.97539832 -1.53093341]\n [-1.         -0.37796447  1.29099445  0.05261351 -1.11141978]\n [ 1.         -0.37796447 -0.77459667  1.64058505  1.7202972 ]\n [-1.         -0.37796447  1.29099445 -0.0813118  -0.16751412]\n [ 1.         -0.37796447 -0.77459667  0.95182631  0.98614835]\n [ 1.         -0.37796447 -0.77459667 -0.59788085 -0.48214934]]\n[[ 0.  0.  0. -1. -1.]\n [ 0.  0.  0.  1.  1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bluewaitor/.virtualenvs/ML-100-Days-VExgN6_H/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# importing dataset 引入数据集\n",
    "dataset = pd.read_csv('./datasets/Data.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "Y = dataset.iloc[:, 3].values\n",
    "\n",
    "# handling the missing data 处理丢失的数据\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(missing_values=\"NaN\", strategy=\"mean\", axis=0)\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "\n",
    "# encoding categorical data 将数据进行编码\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features=[0])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)\n",
    "\n",
    "# splitting the datasets into training sets and Test sets 将数据分为训练集和测试集\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scaling 特征缩放\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
